library(dplyr)
library(lubridate)
library(readxl)
library(rio)        # <- Útil para importar datos
library(car)        # <- Cálculo del VIF y multicolinealidad
library(lmtest)     # <- Necesaria para test de Breusch-Pagan
library(corrplot)   # <- Gráficos matrices de correlación
library(Metrics)
# --- Importar datos ---
datos <- rio::import(file.choose())
head(datos)
# meses a nuemros
meses <- c("Jan", "Feb", "March", "April", "May", "June", "July",
"Aug", "Sept", "Oct", "Nov", "Dec")
datos$mnth <- as.numeric(factor(datos$mnth,
levels = meses))
Mode <- function(x) {
x <- x[!is.na(x)]
if (length(x) == 0) return(NA)
names(sort(table(x), decreasing = TRUE))[1]
}
dias <- datos %>%
group_by(day, mnth, season) %>%
summarise(
holiday = mean(holiday),
weekday = mean(weekday),
workingday = mean(workingday),
weathersit_mode = Mode(weathersit),
temp = mean(temp),
atemp = mean(atemp),
hum = mean(hum),
windspeed = mean(windspeed),
casual = sum(casual),
registered = sum(registered),
bikers = sum(bikers)
)
head(dias)
df <- subset(dias, select = -c(casual, registered))
# Partición de entrenamiento y prueba:
df$partition <- NA  # <- Creamos una nueva columna con NA's
# Armamos una muestra aleatoria para asignar data de entrenamiento y de prueba:
n <- nrow(df)
s <- sample(c(1:n),round(n*0.8,digits=0),replace=FALSE)
df$partition[s] <- 'train'  # <- Rellenamos el 80% con entrenamiento
for(i in 1:n){
if(is.na(df$partition[i]) == TRUE){
df$partition[i] <- 'test'
}
}  # <- Rellenamos el 20% restante con prueba
# Almacenamos la data correspondiente:
data <- subset(df , subset = partition == 'train')
prueba <- subset(df , subset = partition == 'test')
sapply(data, function(x) length(unique(x)))
data <- subset(data, select = -partition)
prueba <- subset(prueba, select = -partition)
# a) Análisis exploratorio
# Resúmenes básicos:
names(data)   # <- Nombres de las variables
head(data)    # <- Visualizar los primeros 6 datos
tail(data)    # <- Visualizar los últimos 6 datos
dim(data)     # <- Retorna número de observaciones y número de variables
# Summary - Info. básica sobre variables:
summary(data$bikers)  # <- Variable a predecir
# Descriptives - Retorna resumen para variables numéricas
descriptives <- psych::describe(dplyr::select(data, where(is.numeric)))# <- Saco las variables no numéricas antes de usarlo
View(descriptives)
# Gráficos
plot(ts(data$bikers))   # <- Vemos como cambia en el tiempo la variable objetivo
boxplot(data$bikers , horizontal = TRUE)   # <- ver el comportamiento de la respuesta y ver al ojo valores atípicos
stripchart(data$bikers, method = "jitter", pch = 19, add = TRUE, col = "blue")
# Visualmente,no tiene datos atípicos. Igual se puede ver el rango intercuartil.
# De todos modos, podemos hacer más preciso el análisis y ver por fechas más detalladas:
boxplot(bikers ~ season, data = data, range = 1.5, pch = 20)
boxplot(bikers ~ mnth, data = data, range = 1.5, pch = 20)
boxplot(bikers ~ weekday, data = data, range = 1.5, pch = 20)
# b) Selección de variables
# Buen paso para empezar -> Ver correlación entre respuesta y predictores candidatos:
data_numeric <- data[ , sapply(data , is.numeric)]  # <- Saco las variables numéricas
cor.base <- cor(data_numeric)                       # <- Cargamos la matriz de correlación
corrplot::corrplot(cor.base,method = "number")
mod2 <- lm(bikers ~ atemp, data)
summary(mod2) # <- Buen ajuste para empezar, notar que r^2 = 0.6101
mod3 <- lm(bikers ~ temp, data)
summary(mod3) # <- Buen ajuste para empezar, notar que r^2 = 0.5991
modelo_completo <- lm(bikers ~ ., data = data)
modelo_nulo <- lm(bikers ~ 1, data = data)
modelo_final_forward <- step(modelo_nulo,
scope = list(lower = ~1, upper = formula(modelo_completo)),
direction = "forward", trace = 0)
modelo_final_back <- step(modelo_completo, direction = "backward")
summary(modelo_final_forward) #r2 = 0.7816
summary(modelo_final_back) #r2 = 0.7827
vif(modelo_final_forward)
vif(modelo_final_back)
summary(modelo_final_back)$adj.r.squared # 0.7781
## supuestos:
res <- residuals(modelo_final_back)
## Normalidad:
shapiro.test(res)
qqnorm(residuals(modelo_final_back))
qqline(residuals(modelo_final_back))
## Homocedasticidad
bptest(modelo_final_back)
plot(modelo_final_back)
RMSE <- sqrt(mean(residuals(modelo_final_back)^2))      # <- 22
MAE <- mean(abs(residuals(modelo_final_back)))
P <- predict(modelo_final_back , newdata = data , drop = F)
R <- data$bikers
P == 0
R == 0   # <- Notemos que el dato 214 es 0
mape(R,P) # <- Mape 21%
P <- predict(modelo_final_back , newdata = prueba , drop = F)
R <- prueba$bikers
mape(R,P) # <- Mape 18% - Importante analizar el resultado!! (es mejorable? ; captura bien la variabilidad? ; no está sobre-ajustado?)
# f) Volvemos a revisar summary, mape, supuestos (básicamente, concluímos)
coef_summary <- summary(modelo_final_back)$coefficients
conf_int <- confint(modelo_final_back, level = 0.95)
# Crear tabla de resultados
resultados <- data.frame(
Variable = rownames(coef_summary),
Coeficiente = coef_summary[, 1],
SE = coef_summary[, 2],
p_valor = coef_summary[, 4],
LI_95 = conf_int[, 1],
LS_95 = conf_int[, 2]
)
resultados
# Hacer predicciones en el conjunto de prueba
predicciones_test <- predict(modelo_final_back, newdata = prueba)
valores_reales_test <- prueba$bikers
# 1) Calcular R² (R-cuadrado)
SS_res <- sum((valores_reales_test - predicciones_test)^2)  # Suma de cuadrados residuales
SS_tot <- sum((valores_reales_test - mean(valores_reales_test))^2)  # Suma de cuadrados totales
R2_test <- 1 - (SS_res / SS_tot)
# 2) Calcular R² ajustado
n_test <- length(valores_reales_test)  # Número de observaciones en test
k <- length(coef(modelo_final_back)) - 1  # Número de predictores (sin intercepto)
R2_adj_test <- 1 - ((1 - R2_test) * (n_test - 1) / (n_test - k - 1))
# 3) Calcular RMSE
RMSE_test <- sqrt(mean((valores_reales_test - predicciones_test)^2))
# 4) Calcular MAE
MAE_test <- mean(abs(valores_reales_test - predicciones_test))
# 5) Calcular MAPE
MAPE_test <- mape(valores_reales_test, predicciones_test)
# ====================================
# MOSTRAR RESULTADOS COMPARATIVOS
# ====================================
# Crear tabla comparativa
comparacion <- data.frame(
Metrica = c("R²", "R² Ajustado", "RMSE", "MAE", "MAPE (%)"),
Entrenamiento = c(
round(summary(modelo_final_back)$r.squared, 4),
round(summary(modelo_final_back)$adj.r.squared, 4),
round(sqrt(mean(residuals(modelo_final_back)^2)), 2),
round(mean(abs(residuals(modelo_final_back))), 2),
round(mape(data$bikers, predict(modelo_final_back, newdata = data)) * 100, 2)
),
Prueba = c(
round(R2_test, 4),
round(R2_adj_test, 4),
round(RMSE_test, 2),
round(MAE_test, 2),
round(MAPE_test * 100, 2)
)
)
print(comparacion)
# También puedes ver gráficamente qué tan bien predice
plot(valores_reales_test, predicciones_test,
xlab = "Valores Reales",
ylab = "Valores Predichos",
main = "Predicciones vs Valores Reales (Test)",
pch = 19, col = "blue")
abline(0, 1, col = "red", lwd = 2)  # Línea de predicción perfecta
